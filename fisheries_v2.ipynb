{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1st-pGEPnMR0X3uco7EkS_AWsEGVXcuLo",
      "authorship_tag": "ABX9TyNInusMXnCL4wgddrTW/oHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mjt216/Sample-Code-Repository/blob/main/fisheries_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R3OXR10GlA9",
        "outputId": "729429c7-ee94-4ffb-8c14-43ba2784e8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  flag  vessels  years_observed  avg_length_m  avg_tonnage_gt  \\\n",
            "0  AFG        5               3     25.134141       64.947881   \n",
            "1  AGO       28               4     31.690469      303.990659   \n",
            "2  AIA        1               2     48.412080      858.707340   \n",
            "3  ALB       22               5     26.754292      135.265132   \n",
            "4  ARE        3               5     23.393464      104.793213   \n",
            "\n",
            "   avg_engine_power_kw  avg_crew_size  total_fishing_hours  total_distance_km  \n",
            "0           530.367414       9.508190          1323.209028       3.101601e+04  \n",
            "1           557.813707      16.149223        182667.782500       1.542720e+06  \n",
            "2          1657.891684      15.767235           428.393194       3.017251e+04  \n",
            "3           488.707395      11.652670         26388.662222       3.375487e+05  \n",
            "4           324.106520      13.176111             7.049167       1.005811e+04  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# STEP 1. High-seas fishing fleet: Read vessel-level data and characterize the fleet by vessel and flag (country).\n",
        "\n",
        "# Load the provided vessel-level data (sample of 100 vessels, all years, all flags)\n",
        "vessel_df = pd.read_csv(\"pnas.2016238117.sd01.csv\")\n",
        "\n",
        "# Clean up and standardize flag states (Flag States = 'flag' column)\n",
        "# Drop rows with missing flags if any\n",
        "vessel_df = vessel_df.dropna(subset=[\"flag\"])\n",
        "\n",
        "# Summarize fleet characteristics by flag (country)\n",
        "flag_summary = vessel_df.groupby(\"flag\").agg(\n",
        "    vessels=(\"mmsi\", \"nunique\"),\n",
        "    years_observed=(\"year\", \"nunique\"),\n",
        "    avg_length_m=(\"length_m\", \"mean\"),\n",
        "    avg_tonnage_gt=(\"tonnage_gt\", \"mean\"),\n",
        "    avg_engine_power_kw=(\"engine_power_kw\", \"mean\"),\n",
        "    avg_crew_size=(\"crew_size\", \"mean\"),\n",
        "    total_fishing_hours=(\"fishing_hours\", \"sum\"),\n",
        "    total_distance_km=(\"distance_traveled_km\", \"sum\"),\n",
        ").reset_index()\n",
        "\n",
        "# Show summary for the first few flag states\n",
        "print(flag_summary.head())\n",
        "\n",
        "# Save output\n",
        "flag_summary.to_csv(\"fleet_summary_by_flag.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the provided vessel-level data\n",
        "vessel_df = pd.read_csv(\"pnas.2016238117.sd01.csv\")\n",
        "\n",
        "# Clean up missing flag or gear type rows if any\n",
        "vessel_df = vessel_df.dropna(subset=[\"flag\", \"gear\"])\n",
        "\n",
        "# Summary by flag\n",
        "flag_summary = vessel_df.groupby(\"flag\").agg(\n",
        "    vessels=(\"mmsi\", \"nunique\"),\n",
        "    years_observed=(\"year\", \"nunique\"),\n",
        "    avg_length_m=(\"length_m\", \"mean\"),\n",
        "    avg_tonnage_gt=(\"tonnage_gt\", \"mean\"),\n",
        "    avg_engine_power_kw=(\"engine_power_kw\", \"mean\"),\n",
        "    avg_crew_size=(\"crew_size\", \"mean\"),\n",
        "    total_fishing_hours=(\"fishing_hours\", \"sum\"),\n",
        "    total_distance_km=(\"distance_traveled_km\", \"sum\"),\n",
        ").reset_index()\n",
        "\n",
        "# Summary by gear type\n",
        "gear_summary = vessel_df.groupby(\"gear\").agg(\n",
        "    vessels=(\"mmsi\", \"nunique\"),\n",
        "    flags=(\"flag\", \"nunique\"),\n",
        "    avg_length_m=(\"length_m\", \"mean\"),\n",
        "    avg_tonnage_gt=(\"tonnage_gt\", \"mean\"),\n",
        "    avg_engine_power_kw=(\"engine_power_kw\", \"mean\"),\n",
        "    avg_crew_size=(\"crew_size\", \"mean\"),\n",
        "    total_fishing_hours=(\"fishing_hours\", \"sum\"),\n",
        "    total_distance_km=(\"distance_traveled_km\", \"sum\"),\n",
        ").reset_index()\n",
        "\n",
        "# Cross-tabulation by flag and gear type\n",
        "flag_gear_summary = vessel_df.groupby([\"flag\", \"gear\"]).agg(\n",
        "    vessels=(\"mmsi\", \"nunique\"),\n",
        "    avg_length_m=(\"length_m\", \"mean\"),\n",
        "    avg_tonnage_gt=(\"tonnage_gt\", \"mean\"),\n",
        "    avg_engine_power_kw=(\"engine_power_kw\", \"mean\"),\n",
        "    avg_crew_size=(\"crew_size\", \"mean\"),\n",
        "    total_fishing_hours=(\"fishing_hours\", \"sum\"),\n",
        ").reset_index()\n",
        "\n",
        "# Save outputs\n",
        "flag_summary.to_csv(\"fleet_summary_by_flag.csv\", index=False)\n",
        "gear_summary.to_csv(\"fleet_summary_by_gear.csv\", index=False)\n",
        "flag_gear_summary.to_csv(\"fleet_summary_by_flag_and_gear.csv\", index=False)\n",
        "\n",
        "# Optionally print head for verification\n",
        "print(\"=== By Flag ===\")\n",
        "print(flag_summary.head())\n",
        "print(\"\\n=== By Gear ===\")\n",
        "print(gear_summary.head())\n",
        "print(\"\\n=== By Flag & Gear ===\")\n",
        "print(flag_gear_summary.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ux6gn7A1g4N",
        "outputId": "f73d344d-e4d5-410a-f16f-461fa0a8a5f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== By Flag ===\n",
            "  flag  vessels  years_observed  avg_length_m  avg_tonnage_gt  \\\n",
            "0  AFG        5               3     25.134141       64.947881   \n",
            "1  AGO       28               4     31.690469      303.990659   \n",
            "2  AIA        1               2     48.412080      858.707340   \n",
            "3  ALB       22               5     26.754292      135.265132   \n",
            "4  ARE        3               5     23.393464      104.793213   \n",
            "\n",
            "   avg_engine_power_kw  avg_crew_size  total_fishing_hours  total_distance_km  \n",
            "0           530.367414       9.508190          1323.209028       3.101601e+04  \n",
            "1           557.813707      16.149223        182667.782500       1.542720e+06  \n",
            "2          1657.891684      15.767235           428.393194       3.017251e+04  \n",
            "3           488.707395      11.652670         26388.662222       3.375487e+05  \n",
            "4           324.106520      13.176111             7.049167       1.005811e+04  \n",
            "\n",
            "=== By Gear ===\n",
            "                 gear  vessels  flags  avg_length_m  avg_tonnage_gt  \\\n",
            "0      dredge_fishing      486     39     24.222357      131.025853   \n",
            "1  drifting_longlines     4024    107     34.380937      276.761252   \n",
            "2           driftnets       14      5     43.231698      398.421075   \n",
            "3             fishing     3392     96     23.156735      192.375154   \n",
            "4          fixed_gear     1046     50     15.353014       63.482091   \n",
            "\n",
            "   avg_engine_power_kw  avg_crew_size  total_fishing_hours  total_distance_km  \n",
            "0           411.932673       5.691466         9.605952e+05       1.295920e+07  \n",
            "1           608.282317      16.818877         3.543466e+07       5.097298e+08  \n",
            "2           780.211437      20.788965         2.513302e+04       4.460970e+05  \n",
            "3           442.434600      10.395961         5.774048e+06       9.804624e+07  \n",
            "4           245.305055       7.667899         1.583288e+06       2.466689e+07  \n",
            "\n",
            "=== By Flag & Gear ===\n",
            "  flag                gear  vessels  avg_length_m  avg_tonnage_gt  \\\n",
            "0  AFG  drifting_longlines        2     30.882431       58.068368   \n",
            "1  AFG       set_longlines        1     33.775641       68.377236   \n",
            "2  AFG            trawlers        2     20.099621       67.530298   \n",
            "3  AGO  drifting_longlines        1     33.052712      203.406615   \n",
            "4  AGO             fishing        2     26.164252      173.433569   \n",
            "\n",
            "   avg_engine_power_kw  avg_crew_size  total_fishing_hours  \n",
            "0           707.225269       9.645994           273.769722  \n",
            "1           811.033550      11.640819             5.189583  \n",
            "2           371.771953       8.906130          1044.249722  \n",
            "3           765.011715      14.121351           757.856944  \n",
            "4           581.930240      11.622857          4431.240278  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the vessel-level data\n",
        "vessel_df = pd.read_csv(\"pnas.2016238117.sd01.csv\")\n",
        "\n",
        "# Clean data for analysis\n",
        "vessel_df = vessel_df.dropna(subset=[\"flag\", \"gear\", \"length_m\", \"tonnage_gt\", \"engine_power_kw\", \"crew_size\"])\n",
        "\n",
        "# STEP 1 continued: Gear type summaries already done.\n",
        "# STEP 2: Length, tonnage, engine power (check, fill missing if necessary)\n",
        "\n",
        "# Check for missing values in key fields\n",
        "missing_length = vessel_df[\"length_m\"].isnull().sum()\n",
        "missing_tonnage = vessel_df[\"tonnage_gt\"].isnull().sum()\n",
        "missing_engine_power = vessel_df[\"engine_power_kw\"].isnull().sum()\n",
        "\n",
        "print(f\"Missing length: {missing_length}, tonnage: {missing_tonnage}, engine_power: {missing_engine_power}\")\n",
        "\n",
        "# If missing values, fill using regression (if necessary; here, just report, not fill, as per user instruction)\n",
        "# For this sample, proceed with available data.\n",
        "\n",
        "# --- Nonlinear relationships (fig. S1) ---\n",
        "# A. Relationship between length and engine power\n",
        "#    engine_power_kw = a + b*length_m + c*length_m^2 (from fig. S1E, or use actual vessel data)\n",
        "\n",
        "# Example: Fit quadratic regression (length vs engine power)\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X = vessel_df[[\"length_m\"]]\n",
        "X_quad = np.column_stack([X, X**2])\n",
        "y = vessel_df[\"engine_power_kw\"]\n",
        "\n",
        "reg = LinearRegression().fit(X_quad, y)\n",
        "print(\"Quadratic model: engine_power_kw = {:.2f} + {:.4f}*length_m + {:.6f}*length_m^2\".format(\n",
        "    reg.intercept_, reg.coef_[0], reg.coef_[1]\n",
        "))\n",
        "\n",
        "# B. Relationship between length and tonnage (optional: fit if needed)\n",
        "X_ton = vessel_df[[\"length_m\"]]\n",
        "X_ton_quad = np.column_stack([X_ton, X_ton**2])\n",
        "y_ton = vessel_df[\"tonnage_gt\"]\n",
        "\n",
        "reg_ton = LinearRegression().fit(X_ton_quad, y_ton)\n",
        "print(\"Quadratic model: tonnage_gt = {:.2f} + {:.4f}*length_m + {:.6f}*length_m^2\".format(\n",
        "    reg_ton.intercept_, reg_ton.coef_[0], reg_ton.coef_[1]\n",
        "))\n",
        "\n",
        "# Save regression coefficients for later use (imputation if needed)\n",
        "np.savez(\"vessel_length_regressions.npz\",\n",
        "         engine_power_intercept=reg.intercept_,\n",
        "         engine_power_coef=reg.coef_,\n",
        "         tonnage_intercept=reg_ton.intercept_,\n",
        "         tonnage_coef=reg_ton.coef_)\n",
        "\n",
        "# If desired: Use these models to fill missing values in a larger dataset.\n",
        "\n",
        "# Save cleaned vessel table for further processing\n",
        "vessel_df.to_csv(\"vessels_cleaned.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFz512Jz1yvA",
        "outputId": "b18c24fd-5ac0-4063-9082-2608c34f900f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing length: 0, tonnage: 0, engine_power: 0\n",
            "Quadratic model: engine_power_kw = 24.43 + 5.7042*length_m + 0.387184*length_m^2\n",
            "Quadratic model: tonnage_gt = 233.39 + -21.3452*length_m + 0.625255*length_m^2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the cleaned vessel-level data\n",
        "vessel_df = pd.read_csv(\"vessels_cleaned.csv\")\n",
        "\n",
        "# STEP: Auxiliary engine power\n",
        "\n",
        "# According to the methods:\n",
        "# - For fishing vessels of the high seas fleet, the average auxiliary engine power represents 47% of the power of the main engine.\n",
        "# - For bunker and reefer vessels: use 24% (not present in this data sample; only fishing vessels expected here).\n",
        "\n",
        "# Add auxiliary engine power field\n",
        "vessel_df[\"aux_engine_power_kw\"] = vessel_df[\"engine_power_kw\"] * 0.47\n",
        "\n",
        "# Save output for further use\n",
        "vessel_df.to_csv(\"vessels_with_aux_power.csv\", index=False)\n",
        "\n",
        "print(vessel_df[[\"mmsi\", \"engine_power_kw\", \"aux_engine_power_kw\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMd-DSqYGo6w",
        "outputId": "58af902b-faff-4410-f462-7fc6c54df216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        mmsi  engine_power_kw  aux_engine_power_kw\n",
            "0  416180800       996.258976           468.241719\n",
            "1  416180800       996.258976           468.241719\n",
            "2  416180800       996.258976           468.241719\n",
            "3  416243500       726.657904           341.529215\n",
            "4  416243500       726.657904           341.529215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load previous data with auxiliary engine power\n",
        "vessel_df = pd.read_csv(\"vessels_with_aux_power.csv\")\n",
        "\n",
        "# STEP: Crew\n",
        "# Use the observed/reported crew_size field directly from data\n",
        "\n",
        "# Check for missing crew_size values\n",
        "missing_crew = vessel_df[\"crew_size\"].isnull().sum()\n",
        "if missing_crew > 0:\n",
        "    print(f\"Warning: {missing_crew} rows have missing crew_size. These will remain NaN.\")\n",
        "\n",
        "# For downstream steps, crew_size is already present\n",
        "# Optionally, ensure field is integer (crew size should be a count)\n",
        "vessel_df[\"crew_size\"] = vessel_df[\"crew_size\"].round().astype(\"Int64\")\n",
        "\n",
        "# Save for next stages\n",
        "vessel_df.to_csv(\"vessels_with_crew_size.csv\", index=False)\n",
        "\n",
        "print(vessel_df[[\"mmsi\", \"crew_size\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO0HRx8uG59l",
        "outputId": "964ad82f-9d08-47fe-cd3a-82245d771520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        mmsi  crew_size\n",
            "0  416180800         35\n",
            "1  416180800         35\n",
            "2  416180800         35\n",
            "3  416243500         19\n",
            "4  416243500         19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data with auxiliary engine power and crew size\n",
        "vessel_df = pd.read_csv(\"vessels_with_crew_size.csv\")\n",
        "\n",
        "# STEP: Design speed\n",
        "# Formula (from supplement):\n",
        "# S_design = 10.4818 + 1.2e-3 * Engine Power - 3.84e-8 * (Engine Power)^2\n",
        "#           (Engine Power in kW, Design speed in knots)\n",
        "\n",
        "vessel_df[\"design_speed_knots\"] = (\n",
        "    10.4818 +\n",
        "    1.2e-3 * vessel_df[\"engine_power_kw\"] -\n",
        "    3.84e-8 * vessel_df[\"engine_power_kw\"]**2\n",
        ")\n",
        "\n",
        "# Save for next stages\n",
        "vessel_df.to_csv(\"vessels_with_design_speed.csv\", index=False)\n",
        "\n",
        "print(vessel_df[[\"mmsi\", \"engine_power_kw\", \"design_speed_knots\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auPrC7qiJ_E-",
        "outputId": "7f474df2-b6d0-4c40-eefb-a68708abbd42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        mmsi  engine_power_kw  design_speed_knots\n",
            "0  416180800       996.258976           11.639198\n",
            "1  416180800       996.258976           11.639198\n",
            "2  416180800       996.258976           11.639198\n",
            "3  416243500       726.657904           11.333513\n",
            "4  416243500       726.657904           11.333513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data with design speed\n",
        "vessel_df = pd.read_csv(\"vessels_with_design_speed.csv\")\n",
        "\n",
        "# STEP: Specific fuel consumption (SFC)\n",
        "# Rules from supplement:\n",
        "# - Country-level SFC (g/kWh) if available:\n",
        "#     China: 280, EU member states: 270, Iceland: 250, Norway: 250, South Korea: 260, Russia: 250\n",
        "# - Else, by vessel length:\n",
        "#     <12 m: 240\n",
        "#     12-24 m: 220\n",
        "#     >24 m: 180\n",
        "# - For auxiliary engines: EEA value (203 g/kWh)\n",
        "# - For bunkers/reefers: use country-specific if possible, else 203 (not present here)\n",
        "\n",
        "country_sfc = {\n",
        "    \"CHN\": 280,\n",
        "    \"China\": 280,\n",
        "    \"EU\": 270,  # For demonstration; actual country list should be expanded for member states\n",
        "    \"ISL\": 250,\n",
        "    \"Iceland\": 250,\n",
        "    \"NOR\": 250,\n",
        "    \"Norway\": 250,\n",
        "    \"KOR\": 260,\n",
        "    \"South Korea\": 260,\n",
        "    \"RUS\": 250,\n",
        "    \"Russia\": 250,\n",
        "}\n",
        "\n",
        "# Helper function to get SFC\n",
        "def get_sfc(row):\n",
        "    flag = row[\"flag\"]\n",
        "    length = row[\"length_m\"]\n",
        "    # Use country SFC if available\n",
        "    for k, v in country_sfc.items():\n",
        "        if flag.strip().upper().startswith(k):\n",
        "            return v\n",
        "    # Else, use length rules\n",
        "    if length < 12:\n",
        "        return 240\n",
        "    elif 12 <= length <= 24:\n",
        "        return 220\n",
        "    else:\n",
        "        return 180\n",
        "\n",
        "# Compute main engine SFC\n",
        "vessel_df[\"sfc_main_g_per_kwh\"] = vessel_df.apply(get_sfc, axis=1)\n",
        "\n",
        "# Auxiliary engine SFC: use 203 for all\n",
        "vessel_df[\"sfc_aux_g_per_kwh\"] = 203\n",
        "\n",
        "# Save for next steps\n",
        "vessel_df.to_csv(\"vessels_with_sfc.csv\", index=False)\n",
        "\n",
        "print(vessel_df[[\"mmsi\", \"flag\", \"length_m\", \"sfc_main_g_per_kwh\", \"sfc_aux_g_per_kwh\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVpsyJJYKW9G",
        "outputId": "d3e91a9b-83ed-4481-955f-50cb85b57c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        mmsi flag   length_m  sfc_main_g_per_kwh  sfc_aux_g_per_kwh\n",
            "0  416180800  TWN  56.130000                 180                203\n",
            "1  416180800  TWN  56.130000                 180                203\n",
            "2  416180800  TWN  56.130000                 180                203\n",
            "3  416243500  TWN  34.479351                 180                203\n",
            "4  416243500  TWN  34.479351                 180                203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# STEP: Fishing effort\n",
        "# Use the provided gridded daily effort data (mmsi-daily-csvs-10-v3-2012-01-01_sample_100.csv)\n",
        "\n",
        "# Load cell-level daily effort data\n",
        "effort_df = pd.read_csv(\"fisingEffort_combined_output_2012.csv\")\n",
        "\n",
        "# Aggregate fishing effort per vessel (mmsi)\n",
        "vessel_effort = effort_df.groupby(\"mmsi\").agg(\n",
        "    total_hours=(\"hours\", \"sum\"),\n",
        "    total_fishing_hours=(\"fishing_hours\", \"sum\"),\n",
        "    days_active=(\"date\", \"nunique\"),\n",
        "    cells_visited=(\"cell_ll_lat\", \"count\"),\n",
        ").reset_index()\n",
        "\n",
        "# Save for further merging with vessel characteristics\n",
        "vessel_effort.to_csv(\"mmsi_fishing_effort_summary_2012.csv\", index=False)\n",
        "\n",
        "print(vessel_effort.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8raJ06GMyrg",
        "outputId": "0042faf7-a03b-4acd-aa27-52d473d3a04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mmsi  total_hours  total_fishing_hours  days_active  cells_visited\n",
            "0   803     330.9739              38.6777           24            107\n",
            "1  3060     712.1620             329.4629           46            177\n",
            "2  3196     349.4322             240.1968           34             89\n",
            "3  3659     451.9190             233.2421           35            107\n",
            "4  5440    6713.4695             937.9891          287           1142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# MERGE calculated datasets\n",
        "\n",
        "# Load vessel master table\n",
        "vessel_df = pd.read_csv(\"vessels_with_sfc.csv\")\n",
        "# Load daily gridded fishing effort summary\n",
        "vessel_effort = pd.read_csv(\"mmsi_fishing_effort_summary_2012.csv\")\n",
        "\n",
        "# Merge effort data into vessel table by 'mmsi'\n",
        "vessel_df = vessel_df.merge(vessel_effort, on=\"mmsi\", how=\"left\")\n",
        "\n",
        "# Check merge results\n",
        "print(vessel_df[[\"mmsi\", \"total_fishing_hours\", \"days_active\", \"cells_visited\"]].head())\n",
        "\n",
        "# Save merged table for downstream economic calculations\n",
        "vessel_df.to_csv(\"vessels_with_effort_2012.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qq3AgT5NEod",
        "outputId": "8e764116-7073-49a3-ad51-eff605df7d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        mmsi  total_fishing_hours  days_active  cells_visited\n",
            "0  416180800                  NaN          NaN            NaN\n",
            "1  416180800                  NaN          NaN            NaN\n",
            "2  416180800                  NaN          NaN            NaN\n",
            "3  416243500                  NaN          NaN            NaN\n",
            "4  416243500                  NaN          NaN            NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# STEP encounters\n",
        "\n",
        "# Load vessel master table (with gear, flag, etc.)\n",
        "vessel_df = pd.read_csv(\"vessels_with_effort_2012.csv\")\n",
        "\n",
        "# Load carrier and bunker encounters\n",
        "# Reload the original encounter files to ensure 'neighbor_mmsi' and 'carrier_mmsi' are present\n",
        "carrier_encounters = pd.read_csv(\"carrier_encounters_v20210408.csv\")\n",
        "bunker_encounters = pd.read_csv(\"bunker_encounters_v20210408.csv\")\n",
        "\n",
        "# Map neighbor (fishing) vessel MMSI in encounters to fleet/flag and gear type\n",
        "# Ensure 'mmsi', 'flag', and 'gear' are selected from vessel_df for merging\n",
        "fleet_cols = [\"mmsi\", \"flag\", \"gear\"]\n",
        "\n",
        "# --- Carrier (reefer) encounters: join fishing vessel info ---\n",
        "# The join should be on 'neighbor_mmsi' from carrier_encounters and 'mmsi' from vessel_df\n",
        "carrier_encounters = carrier_encounters.merge(\n",
        "    vessel_df[fleet_cols],\n",
        "    left_on=\"neighbor_mmsi\",\n",
        "    right_on=\"mmsi\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# --- Bunker encounters: join fishing vessel info ---\n",
        "# The join should be on 'neighbor_ssvid' from bunker_encounters and 'mmsi' from vessel_df\n",
        "bunker_encounters = bunker_encounters.merge(\n",
        "    vessel_df[fleet_cols],\n",
        "    left_on=\"neighbor_ssvid\",\n",
        "    right_on=\"mmsi\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# --- Aggregation: by flag (fleet) and gear type ---\n",
        "# Ensure the columns for aggregation exist after the merge. The merge adds 'flag' and 'gear' from vessel_df.\n",
        "carrier_fleet_gear_summary = carrier_encounters.groupby([\"flag\", \"gear\"]).agg(\n",
        "    n_encounters=(\"event\", \"count\"),\n",
        "    mean_duration_hr=(\"event_duration_hr\", \"mean\"),\n",
        "    total_duration_hr=(\"event_duration_hr\", \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "bunker_fleet_gear_summary = bunker_encounters.groupby([\"flag\", \"gear\"]).agg(\n",
        "    n_encounters=(\"event\", \"count\"),\n",
        "    mean_duration_hr=(\"event_duration_hr\", \"mean\"),\n",
        "    total_duration_hr=(\"event_duration_hr\", \"sum\")\n",
        ").reset_index()\n",
        "\n",
        "\n",
        "# Save outputs\n",
        "carrier_fleet_gear_summary.to_csv(\"carrier_encounter_summary_by_fleet_and_gear_2012.csv\", index=False)\n",
        "bunker_fleet_gear_summary.to_csv(\"bunker_encounter_summary_by_fleet_and_gear_2012.csv\", index=False)\n",
        "\n",
        "print(\"Carrier encounters by fleet/flag and gear:\")\n",
        "print(carrier_fleet_gear_summary.head())\n",
        "print(\"\\nBunker encounters by fleet/flag and gear:\")\n",
        "print(bunker_fleet_gear_summary.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYdG8XUNOkDD",
        "outputId": "11675702-ba62-4d2d-be1d-16de5e557920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carrier encounters by fleet/flag and gear:\n",
            "  flag                gear  n_encounters  mean_duration_hr  total_duration_hr\n",
            "0  BLZ            trawlers            20         30.725000         614.500000\n",
            "1  CHN  drifting_longlines          3929          8.076822       31733.833334\n",
            "2  CHN             fishing           246         26.369919        6487.000000\n",
            "3  CHN          fixed_gear             8          3.666667          29.333333\n",
            "4  CHN        set_gillnets            11          8.984848          98.833333\n",
            "\n",
            "Bunker encounters by fleet/flag and gear:\n",
            "  flag                gear  n_encounters  mean_duration_hr  total_duration_hr\n",
            "0  BES  drifting_longlines             4          4.166667          16.666667\n",
            "1  BLZ            trawlers            19          8.447368         160.500000\n",
            "2  BLZ   tuna_purse_seines           119          4.624650         550.333333\n",
            "3  CAN             fishing             5         11.666667          58.333333\n",
            "4  CHL   tuna_purse_seines             3          2.666667           8.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#STEP fishing revenue\n",
        "\n",
        "# --- Load data ---\n",
        "# Sample value data (landed value by country, species, area, year, etc.)\n",
        "value_df = pd.read_csv(\"SAU FAO 18 v50-1.csv\")\n",
        "\n",
        "# Sample catch amount (live weight in tonnes, by country, species, area, year)\n",
        "# Added encoding='latin-1' to handle potential encoding issues\n",
        "# Fixed separator to comma based on error and column inspection\n",
        "# Try reading with different separator and engine\n",
        "try:\n",
        "    # Try comma separation first (already did, but good to keep)\n",
        "    catch_df = pd.read_csv(\"capture_by_FAOMajorFishingArea.csv\", sep=\",\", encoding='latin-1')\n",
        "    # Check if columns are parsed correctly\n",
        "    if len(catch_df.columns) == 1:\n",
        "         raise ValueError(\"Columns not parsed correctly with comma separator\")\n",
        "except:\n",
        "    # If comma separation failed, try tab separation\n",
        "    try:\n",
        "        catch_df = pd.read_csv(\"capture_by_FAOMajorFishingArea.csv\", sep=\"\\t\", encoding='latin-1')\n",
        "        if len(catch_df.columns) == 1:\n",
        "             raise ValueError(\"Columns not parsed correctly with tab separator\")\n",
        "    except:\n",
        "        # If both failed, let pandas auto-detect (slower)\n",
        "        catch_df = pd.read_csv(\"capture_by_FAOMajorFishingArea.csv\", sep=None, engine='python', encoding='latin-1')\n",
        "\n",
        "\n",
        "# Drop the 'S' columns next to the year columns\n",
        "catch_df = catch_df.drop(columns=[col for col in catch_df.columns if col.endswith(',S')])\n",
        "\n",
        "# --- Clean and harmonize columns for merge ---\n",
        "# Value data: focus on key columns for merge\n",
        "value_df[\"year\"] = value_df[\"year\"].astype(str)\n",
        "value_df[\"country\"] = value_df[\"fishing_entity\"]\n",
        "value_df[\"species\"] = value_df[\"common_name\"]\n",
        "value_df[\"area\"] = value_df[\"area_name\"]\n",
        "\n",
        "# Catch data: melt to long format for year columns\n",
        "year_cols = [col for col in catch_df.columns if col.startswith(\"[\") and col.endswith(\"]\")]\n",
        "catch_long = catch_df.melt(\n",
        "    id_vars=[\"Country (Name)\", \"ASFIS species (Name)\", \"FAO major fishing area (Name)\", \"Unit (Name)\", \"Unit\"],\n",
        "    value_vars=year_cols,\n",
        "    var_name=\"year\",\n",
        "    value_name=\"value\" # Corrected: value_name should be 'value' based on previous output\n",
        ")\n",
        "\n",
        "# Print columns of catch_long to debug\n",
        "print(\"Columns of catch_long after melt:\")\n",
        "print(catch_long.columns)\n",
        "\n",
        "\n",
        "catch_long[\"year\"] = catch_long[\"year\"].str.extract(r\"\\[(\\d{4})\\]\").astype(str)\n",
        "catch_long[\"country\"] = catch_long[\"Country (Name)\"]\n",
        "catch_long[\"species\"] = catch_long[\"ASFIS species (Name)\"]\n",
        "catch_long[\"area\"] = catch_long[\"FAO major fishing area (Name)\"]\n",
        "\n",
        "# --- Debugging: Inspect merge key columns ---\n",
        "print(\"\\n--- Debugging Merge Keys ---\")\n",
        "print(\"Unique values in catch_long['country']:\", catch_long['country'].unique()[:20]) # Print first 20 unique values\n",
        "print(\"Unique values in value_df['country']:\", value_df['country'].unique()[:20]) # Print first 20 unique values\n",
        "print(\"Unique values in catch_long['species']:\", catch_long['species'].unique()[:20]) # Print first 20 unique values\n",
        "print(\"Unique values in value_df['species']:\", value_df['species'].unique()[:20]) # Print first 20 unique values\n",
        "print(\"Unique values in catch_long['area']:\", catch_long['area'].unique()[:20]) # Print first 20 unique values\n",
        "print(\"Unique values in value_df['area']:\", value_df['area'].unique()[:20]) # Print first 20 unique values\n",
        "print(\"Unique values in catch_long['year']:\", catch_long['year'].unique()[:20]) # Print first 20 unique values\n",
        "print(\"Unique values in value_df['year']:\", value_df['year'].unique()[:20]) # Print first 20 unique values\n",
        "print(\"Data type of catch_long['country']:\", catch_long['country'].dtype)\n",
        "print(\"Data type of value_df['country']:\", value_df['country'].dtype)\n",
        "print(\"Data type of catch_long['species']:\", catch_long['species'].dtype)\n",
        "print(\"Data type of value_df['species']:\", value_df['species'].dtype)\n",
        "print(\"Data type of catch_long['area']:\", catch_long['area'].dtype)\n",
        "print(\"Data type of value_df['area']:\", value_df['area'].dtype)\n",
        "print(\"Data type of catch_long['year']:\", catch_long['year'].dtype)\n",
        "print(\"Data type of value_df['year']:\", value_df['year'].dtype)\n",
        "\n",
        "\n",
        "# --- Merge: for all years, by country, species, and area ---\n",
        "# Remove the year filtering for both dataframes\n",
        "merged = pd.merge(\n",
        "    catch_long, # Use catch_long with all years\n",
        "    value_df, # Use value_df with all years\n",
        "    on=[\"country\", \"species\", \"area\", \"year\"], # Merge on year as well\n",
        "    how=\"left\",\n",
        "    suffixes=(\"_catch\", \"_value\")\n",
        ")\n",
        "\n",
        "# --- Output: Key columns for analysis ---\n",
        "# Corrected: Use 'value' instead of 'tonnes'\n",
        "result = merged[[\n",
        "    \"country\", \"species\", \"area\", \"year\", \"value\", \"landed_value\"\n",
        "]]\n",
        "\n",
        "# Update the output filename to reflect all years\n",
        "result.to_csv(\"catch_value_merged_all_years.csv\", index=False)\n",
        "print(result.head())\n",
        "print(result[result[\"landed_value\"].notna()].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJLpPUcFU6Pr",
        "outputId": "a92dad53-18ef-4e6f-d84f-9f6ec799d19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns of catch_long after melt:\n",
            "Index(['Country (Name)', 'ASFIS species (Name)',\n",
            "       'FAO major fishing area (Name)', 'Unit (Name)', 'Unit', 'year',\n",
            "       'value'],\n",
            "      dtype='object')\n",
            "\n",
            "--- Debugging Merge Keys ---\n",
            "Unique values in catch_long['country']: ['Afghanistan' 'Albania' 'Algeria' 'American Samoa' 'Andorra' 'Angola'\n",
            " 'Anguilla' 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Aruba'\n",
            " 'Ascension, Saint Helena and Tristan da Cunha' 'Australia' 'Austria'\n",
            " 'Azerbaijan' 'Bahamas' 'Bahrain' 'Bangladesh' 'Barbados' 'Belarus']\n",
            "Unique values in value_df['country']: ['Canada' 'Russian Federation' 'USA']\n",
            "Unique values in catch_long['species']: ['Freshwater fishes NEI' 'Angelsharks, sand devils NEI'\n",
            " 'Atlantic bluefin tuna' 'Atlantic bonito' 'Barracudas NEI' 'Bighead carp'\n",
            " 'Bleak' 'Blue and red shrimp' 'Blue crab' 'Blue whiting(=Poutassou)'\n",
            " 'Bluefish' 'Bogue' 'Caramote prawn' 'Catsharks, nursehounds NEI'\n",
            " 'Common carp' 'Common cuttlefish' 'Common dace' 'Common dentex'\n",
            " 'Common octopus' 'Common sole']\n",
            "Unique values in value_df['species']: ['Marine fishes nei' 'Smelts' 'Cods, haddocks' 'Sculpins' 'Whitefishes'\n",
            " 'Atlantic salmon' 'Pink salmon' 'Chum salmon' 'Coho salmon' 'Arctic char'\n",
            " 'Saffron cod' 'Polar cod' 'Greenland halibut' 'Pacific herring'\n",
            " 'Arctic cisco' 'Broad whitefish' 'Humpback whitefish' 'Sardine cisco'\n",
            " 'Dolly varden' 'Sheefish']\n",
            "Unique values in catch_long['area']: ['Asia - Inland waters' 'Mediterranean and Black Sea'\n",
            " 'Europe - Inland waters' 'Africa - Inland waters'\n",
            " 'Pacific, Eastern Central' 'Oceania - Inland waters'\n",
            " 'Atlantic, Southeast' 'Atlantic, Eastern Central'\n",
            " 'Atlantic, Western Central' 'America, North - Inland waters'\n",
            " 'America, South - Inland waters' 'Atlantic, Antarctic'\n",
            " 'Atlantic, Southwest' 'Pacific, Antarctic'\n",
            " 'Marine areas outside the Antarctic' 'Antarctic areas NEI'\n",
            " 'Pacific, Southeast' 'Indian Ocean, Antarctic' 'Indian Ocean, Eastern'\n",
            " 'Pacific, Southwest']\n",
            "Unique values in value_df['area']: ['Arctic Sea']\n",
            "Unique values in catch_long['year']: ['2010' '2011' '2012' '2013' '2014' '2015' '2016' '2017' '2018' '2019'\n",
            " '2020' '2021' '2022' '2023']\n",
            "Unique values in value_df['year']: ['1950' '1951' '1952' '1953' '1954' '1955' '1956' '1957' '1958' '1959'\n",
            " '1960' '1961' '1962' '1963' '1964' '1965' '1966' '1967' '1968' '1969']\n",
            "Data type of catch_long['country']: object\n",
            "Data type of value_df['country']: object\n",
            "Data type of catch_long['species']: object\n",
            "Data type of value_df['species']: object\n",
            "Data type of catch_long['area']: object\n",
            "Data type of value_df['area']: object\n",
            "Data type of catch_long['year']: object\n",
            "Data type of value_df['year']: object\n",
            "       country                       species                         area  \\\n",
            "0  Afghanistan         Freshwater fishes NEI         Asia - Inland waters   \n",
            "1      Albania  Angelsharks, sand devils NEI  Mediterranean and Black Sea   \n",
            "2      Albania         Atlantic bluefin tuna  Mediterranean and Black Sea   \n",
            "3      Albania               Atlantic bonito  Mediterranean and Black Sea   \n",
            "4      Albania                Barracudas NEI  Mediterranean and Black Sea   \n",
            "\n",
            "   year   value  landed_value  \n",
            "0  2010  1000.0           NaN  \n",
            "1  2010    78.0           NaN  \n",
            "2  2010     0.0           NaN  \n",
            "3  2010    23.0           NaN  \n",
            "4  2010     7.0           NaN  \n",
            "Empty DataFrame\n",
            "Columns: [country, species, area, year, value, landed_value]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# STEP LABOR\n",
        "\n",
        "# Load your vessel data (should contain at least: mmsi, flag, crew_size, days_active, main_fuel_kg, aux_fuel_kg, total_fishing_hours, etc.)\n",
        "vessel_df = pd.read_csv(\"vessels_with_effort.csv\")  # <-- Update with actual vessel CSV filename\n",
        "\n",
        "# Load labor data (monthly wage per country, USD/month)\n",
        "labor = pd.read_csv(\"EAR_4MTH_SEX_OCU_CUR_NB_A-filtered-2025-06-27.csv\")\n",
        "\n",
        "# Clean labor columns for easier usage\n",
        "labor.columns = [c.replace('\"', '').replace('.', '').replace(' ', '_').replace('(', '').replace(')', '').replace('-', '_').replace(',', '').replace(':', '').lower() for c in labor.columns]\n",
        "# Now labor['ref_area_label'] is country, labor['time'] = year, labor['obs_value'] = wage (USD/month)\n",
        "\n",
        "# Keep only most recent wage per country (drop rows with missing obs_value)\n",
        "labor = labor.dropna(subset=[\"obs_value\"])\n",
        "# Correct the column name to 'ref_arealabel' based on the variable explorer\n",
        "labor_recent = labor.sort_values(\"time\").groupby(\"ref_arealabel\").tail(1)  # most recent year per country\n",
        "\n",
        "# Make a mapping from country to wage\n",
        "country_to_wage = dict(zip(labor_recent[\"ref_arealabel\"], labor_recent[\"obs_value\"]))\n",
        "\n",
        "# Map vessel flag to wage (requires consistent country naming)\n",
        "# If vessel_df 'flag' field uses ISO3, map to country names\n",
        "iso_map = {\n",
        "    \"CHN\": \"China\",\n",
        "    \"KOR\": \"Republic of Korea\",\n",
        "    \"RUS\": \"Russian Federation\",\n",
        "    \"ESP\": \"Spain\",\n",
        "    \"ISL\": \"Iceland\",\n",
        "    \"NOR\": \"Norway\",\n",
        "    # Add any other mappings as needed\n",
        "}\n",
        "def get_country_name(flag):\n",
        "    return iso_map.get(flag, flag)\n",
        "\n",
        "# Add country name column for mapping\n",
        "vessel_df[\"country_name\"] = vessel_df[\"flag\"].apply(get_country_name)\n",
        "vessel_df[\"monthly_wage_usd\"] = vessel_df[\"country_name\"].map(country_to_wage)\n",
        "\n",
        "# If missing, fill with a global median or mean\n",
        "median_wage = labor_recent[\"obs_value\"].median()\n",
        "vessel_df[\"monthly_wage_usd\"] = vessel_df[\"monthly_wage_usd\"].fillna(median_wage)\n",
        "\n",
        "# Update crew cost calculation: crew_size * days_active/30 * wage\n",
        "vessel_df[\"crew_cost_usd\"] = vessel_df[\"crew_size\"] * (vessel_df[\"days_active\"] * (vessel_df[\"monthly_wage_usd\"] / 30))\n",
        "\n",
        "# Save updated output (does not include cost or profit yet)\n",
        "vessel_df.to_csv(\"vessels_with_updated_wages.csv\", index=False)\n",
        "\n",
        "# Print sample output for verification\n",
        "print(vessel_df[[\n",
        "    \"mmsi\", \"flag\", \"country_name\", \"monthly_wage_usd\",\n",
        "    \"crew_size\", \"days_active\", \"crew_cost_usd\"\n",
        "]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieMlw21qVGAG",
        "outputId": "d251d3b2-68b4-4e1a-d257-a1fc1690d12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        mmsi flag country_name  monthly_wage_usd  crew_size  days_active  \\\n",
            "0  416180800  TWN          TWN          334.7695         35          NaN   \n",
            "1  416180800  TWN          TWN          334.7695         35          NaN   \n",
            "2  416180800  TWN          TWN          334.7695         35          NaN   \n",
            "3  416243500  TWN          TWN          334.7695         19          NaN   \n",
            "4  416243500  TWN          TWN          334.7695         19          NaN   \n",
            "\n",
            "   crew_cost_usd  \n",
            "0            NaN  \n",
            "1            NaN  \n",
            "2            NaN  \n",
            "3            NaN  \n",
            "4            NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# PROFIT\n",
        "\n",
        "# --- Load vessel-effort and wage-updated data ---\n",
        "vessel_df = pd.read_csv(\"vessels_with_updated_wages.csv\")\n",
        "\n",
        "# --- Load merged catch amount/value-per-tonne data ---\n",
        "catch_value_df = pd.read_csv(\"catch_amount_value_merged.csv\")\n",
        "\n",
        "# --- Load fuel price data ---\n",
        "fuel_prices = pd.read_csv(\"Daily_Bunker_Fuel_Prices_20250524.csv\")\n",
        "\n",
        "# --- Clean fuel price columns ---\n",
        "# Standardize column names\n",
        "fuel_prices.columns = [c.strip().replace(' ', '_').replace('.', '').replace('%','pct').replace('/', '_').replace('\"','').replace(',','') for c in fuel_prices.columns]\n",
        "# Parse date\n",
        "def parse_date(row):\n",
        "    try:\n",
        "        return datetime.strptime(row['Day'], \"%m/%d/%Y\")\n",
        "    except Exception:\n",
        "        return pd.NaT\n",
        "fuel_prices['date'] = fuel_prices.apply(parse_date, axis=1)\n",
        "# We'll use \"Marine_Gas_Oil\" as the default marine fuel price\n",
        "fuel_prices = fuel_prices.dropna(subset=[\"date\"])\n",
        "fuel_prices = fuel_prices.sort_values(\"date\")\n",
        "fuel_prices['Marine_Gas_Oil'] = pd.to_numeric(fuel_prices['Marine_Gas_Oil'], errors='coerce')\n",
        "\n",
        "# --- Build a mapping from year to mean fuel price (USD/ton) ---\n",
        "fuel_prices['year'] = fuel_prices['date'].dt.year\n",
        "yearly_fuel_price = fuel_prices.groupby('year')[\"Marine_Gas_Oil\"].mean().to_dict()\n",
        "\n",
        "# --- Merge catch value per tonne to vessel_df by flag/country/species/area ---\n",
        "value_map = catch_value_df.groupby(\"fishing_entity\")[\"value_per_tonne\"].median().to_dict()\n",
        "vessel_df[\"value_per_tonne\"] = vessel_df[\"country_name\"].map(value_map)\n",
        "median_value = catch_value_df[\"value_per_tonne\"].median()\n",
        "vessel_df[\"value_per_tonne\"] = vessel_df[\"value_per_tonne\"].fillna(median_value)\n",
        "\n",
        "# --- Estimate catch in tonnes ---\n",
        "catch_per_hour = 0.3  # tons/hour as fallback, update if possible\n",
        "if \"estimated_landings_tons\" not in vessel_df.columns:\n",
        "    vessel_df[\"estimated_landings_tons\"] = vessel_df[\"total_fishing_hours\"] * catch_per_hour\n",
        "\n",
        "# --- Revenue calculation using value_per_tonne from catch data ---\n",
        "vessel_df[\"revenue_usd\"] = vessel_df[\"estimated_landings_tons\"] * vessel_df[\"value_per_tonne\"]\n",
        "\n",
        "# --- Select fuel price by vessel year (or use latest if missing) ---\n",
        "# If vessel_df has a 'year' or 'active_year' column, use it; otherwise, use the latest year in the fuel price data\n",
        "if 'year' in vessel_df.columns:\n",
        "    vessel_df['fuel_price_usd_per_ton'] = vessel_df['year'].map(yearly_fuel_price)\n",
        "else:\n",
        "    latest_year = max(yearly_fuel_price.keys())\n",
        "    vessel_df['fuel_price_usd_per_ton'] = yearly_fuel_price[latest_year]\n",
        "\n",
        "# If any vessel still missing fuel price, fill with overall mean\n",
        "overall_mean_fuel_price = np.nanmean(list(yearly_fuel_price.values()))\n",
        "vessel_df['fuel_price_usd_per_ton'] = vessel_df['fuel_price_usd_per_ton'].fillna(overall_mean_fuel_price)\n",
        "\n",
        "# --- Calculate fuel consumption (kg) ---\n",
        "# Assume load factors: 0.6 for fishing, 0.8 for transit/other activity\n",
        "load_factor_fishing = 0.6\n",
        "load_factor_transit = 0.8\n",
        "\n",
        "# Assuming 'total_hours' is total active hours and 'fishing_hours' is hours spent fishing\n",
        "vessel_df[\"transit_hours\"] = vessel_df[\"total_hours\"] - vessel_df[\"fishing_hours\"]\n",
        "\n",
        "# Fuel consumption (kg) = Power (kW) * SFC (g/kWh) * Hours (h) / 1000 (g/kg) * Load Factor\n",
        "vessel_df[\"main_fuel_kg\"] = (\n",
        "    vessel_df[\"engine_power_kw\"] * vessel_df[\"sfc_main_g_per_kwh\"] *\n",
        "    (vessel_df[\"fishing_hours\"] * load_factor_fishing + vessel_df[\"transit_hours\"] * load_factor_transit) / 1000\n",
        ")\n",
        "\n",
        "vessel_df[\"aux_fuel_kg\"] = (\n",
        "    vessel_df[\"aux_engine_power_kw\"] * vessel_df[\"sfc_aux_g_per_kwh\"] *\n",
        "    vessel_df[\"total_hours\"] / 1000  # Auxiliary engines run during all active hours\n",
        ")\n",
        "\n",
        "\n",
        "# --- Fuel cost calculation using vessel's fuel consumption and year-matched price ---\n",
        "vessel_df[\"total_fuel_tons\"] = (vessel_df[\"main_fuel_kg\"] + vessel_df[\"aux_fuel_kg\"]) / 1000\n",
        "vessel_df[\"fuel_cost_usd\"] = vessel_df[\"total_fuel_tons\"] * vessel_df[\"fuel_price_usd_per_ton\"]\n",
        "\n",
        "# --- Fixed cost ---\n",
        "fixed_cost_per_day = 100\n",
        "vessel_df[\"fixed_cost_usd\"] = vessel_df[\"days_active\"] * fixed_cost_per_day\n",
        "\n",
        "# --- Total cost and profit ---\n",
        "vessel_df[\"total_cost_usd\"] = vessel_df[\"fuel_cost_usd\"] + vessel_df[\"crew_cost_usd\"] + vessel_df[\"fixed_cost_usd\"]\n",
        "vessel_df[\"profit_usd\"] = vessel_df[\"revenue_usd\"] - vessel_df[\"total_cost_usd\"]\n",
        "\n",
        "# --- Save output ---\n",
        "vessel_df.to_csv(\"vessels_with_cost_profit_fuel_by_year.csv\", index=False)\n",
        "\n",
        "# --- Print sample output ---\n",
        "print(vessel_df[[\n",
        "    \"mmsi\", \"flag\", \"country_name\", \"year\" if \"year\" in vessel_df.columns else vessel_df.index,\n",
        "    \"monthly_wage_usd\", \"crew_size\", \"days_active\",\n",
        "    \"crew_cost_usd\", \"main_fuel_kg\", \"aux_fuel_kg\", \"fuel_cost_usd\", \"fuel_price_usd_per_ton\", \"fixed_cost_usd\", \"estimated_landings_tons\",\n",
        "    \"value_per_tonne\", \"revenue_usd\", \"total_cost_usd\", \"profit_usd\"\n",
        "]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t66kMIA3VcJG",
        "outputId": "99649950-bf6b-4981-89e4-950a87415c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        mmsi flag country_name  year  monthly_wage_usd  crew_size  \\\n",
            "0  416180800  TWN          TWN  2015          334.7695         35   \n",
            "1  416180800  TWN          TWN  2016          334.7695         35   \n",
            "2  416180800  TWN          TWN  2017          334.7695         35   \n",
            "3  416243500  TWN          TWN  2013          334.7695         19   \n",
            "4  416243500  TWN          TWN  2014          334.7695         19   \n",
            "\n",
            "   days_active  crew_cost_usd  main_fuel_kg  aux_fuel_kg  fuel_cost_usd  \\\n",
            "0          NaN            NaN           NaN          NaN            NaN   \n",
            "1          NaN            NaN           NaN          NaN            NaN   \n",
            "2          NaN            NaN           NaN          NaN            NaN   \n",
            "3          NaN            NaN           NaN          NaN            NaN   \n",
            "4          NaN            NaN           NaN          NaN            NaN   \n",
            "\n",
            "   fuel_price_usd_per_ton  fixed_cost_usd  estimated_landings_tons  \\\n",
            "0              758.119701             NaN                      NaN   \n",
            "1              758.119701             NaN                      NaN   \n",
            "2              758.119701             NaN                      NaN   \n",
            "3              758.119701             NaN                      NaN   \n",
            "4              758.119701             NaN                      NaN   \n",
            "\n",
            "   value_per_tonne  revenue_usd  total_cost_usd  profit_usd  \n",
            "0              NaN          NaN             NaN         NaN  \n",
            "1              NaN          NaN             NaN         NaN  \n",
            "2              NaN          NaN             NaN         NaN  \n",
            "3              NaN          NaN             NaN         NaN  \n",
            "4              NaN          NaN             NaN         NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmG2jYItdQ8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "8fd060cf",
        "outputId": "f3230055-359a-4922-ccc2-53c75257d7a2"
      },
      "source": [
        "# Filter out rows where profit_usd is NaN\n",
        "vessel_df_filtered = vessel_df.dropna(subset=[\"profit_usd\"])\n",
        "\n",
        "# Display the first few rows of the filtered DataFrame\n",
        "print(\"Filtered DataFrame (first 5 rows):\")\n",
        "display(vessel_df_filtered.head())\n",
        "\n",
        "# Display the shape of the original and filtered DataFrames to show the number of rows removed\n",
        "print(f\"\\nOriginal DataFrame shape: {vessel_df.shape}\")\n",
        "print(f\"Filtered DataFrame shape: {vessel_df_filtered.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered DataFrame (first 5 rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [mmsi, year, flag, gear, engine_power_kw, tonnage_gt, length_m, crew_size, positions, ais_type, foc, iuu, fldb_vessel_id, source_id, years_until_caught, hours, fishing_hours, average_daily_fishing_hours, fishing_hours_foreign_eez, fishing_hours_high_seas, distance_traveled_km, max_distance_from_shore_km, max_distance_from_port_km, number_encounters, number_iuu_encounters, number_forced_labor_encounters, average_encounter_duration_hours, gaps_24_hours, number_voyages, number_foreign_port_visits, number_poc_port_visits, average_voyage_duration_hours, number_loitering_events, average_loitering_duration_hours, offender, aux_engine_power_kw, design_speed_knots, sfc_main_g_per_kwh, sfc_aux_g_per_kwh, total_hours, total_fishing_hours, days_active, cells_visited, country_name, monthly_wage_usd, crew_cost_usd, value_per_tonne, estimated_landings_tons, revenue_usd, fuel_price_usd_per_ton, transit_hours, main_fuel_kg, aux_fuel_kg, total_fuel_tons, fuel_cost_usd, fixed_cost_usd, total_cost_usd, profit_usd]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 58 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0874c445-f925-42e4-9e84-5659ba42a121\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mmsi</th>\n",
              "      <th>year</th>\n",
              "      <th>flag</th>\n",
              "      <th>gear</th>\n",
              "      <th>engine_power_kw</th>\n",
              "      <th>tonnage_gt</th>\n",
              "      <th>length_m</th>\n",
              "      <th>crew_size</th>\n",
              "      <th>positions</th>\n",
              "      <th>ais_type</th>\n",
              "      <th>...</th>\n",
              "      <th>revenue_usd</th>\n",
              "      <th>fuel_price_usd_per_ton</th>\n",
              "      <th>transit_hours</th>\n",
              "      <th>main_fuel_kg</th>\n",
              "      <th>aux_fuel_kg</th>\n",
              "      <th>total_fuel_tons</th>\n",
              "      <th>fuel_cost_usd</th>\n",
              "      <th>fixed_cost_usd</th>\n",
              "      <th>total_cost_usd</th>\n",
              "      <th>profit_usd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 58 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0874c445-f925-42e4-9e84-5659ba42a121')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0874c445-f925-42e4-9e84-5659ba42a121 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0874c445-f925-42e4-9e84-5659ba42a121');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original DataFrame shape: (123648, 58)\n",
            "Filtered DataFrame shape: (0, 58)\n"
          ]
        }
      ]
    }
  ]
}